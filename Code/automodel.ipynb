{"cells":[{"cell_type":"code","source":["!pip install -U ipython"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CVGV_E_RQq9y","executionInfo":{"status":"ok","timestamp":1695828700540,"user_tz":240,"elapsed":6097,"user":{"displayName":"Abhishek Donekal","userId":"08256368135897058810"}},"outputId":"9e3bed09-26bc-4244-dafc-b0b5c10db8ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (8.15.0)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython) (0.2.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython) (4.4.2)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython) (0.19.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython) (0.1.6)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.10/dist-packages (from ipython) (3.0.36)\n","Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython) (2.16.1)\n","Requirement already satisfied: stack-data in /usr/local/lib/python3.10/dist-packages (from ipython) (0.6.2)\n","Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.10/dist-packages (from ipython) (5.7.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython) (1.1.3)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython) (4.8.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython) (0.2.6)\n","Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython) (1.2.0)\n","Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython) (2.4.0)\n","Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython) (0.2.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.1.0->stack-data->ipython) (1.16.0)\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"id":"vllFKBOz83__","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1696044269086,"user_tz":240,"elapsed":47776,"user":{"displayName":"Abhishek Donekal","userId":"08256368135897058810"}},"outputId":"7d296900-9356-4ab9-fc49-cbb930152b14"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting autokeras\n","  Downloading autokeras-1.1.0-py3-none-any.whl (148 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.6/148.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from autokeras) (23.1)\n","Requirement already satisfied: tensorflow>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from autokeras) (2.13.0)\n","Collecting keras-tuner>=1.1.0 (from autokeras)\n","  Downloading keras_tuner-1.4.3-py3-none-any.whl (127 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras-nlp>=0.4.0 (from autokeras)\n","  Downloading keras_nlp-0.6.2-py3-none-any.whl (590 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.1/590.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from autokeras) (1.5.3)\n","Collecting keras-core (from keras-nlp>=0.4.0->autokeras)\n","  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-nlp>=0.4.0->autokeras) (1.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-nlp>=0.4.0->autokeras) (1.23.5)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-nlp>=0.4.0->autokeras) (2023.6.3)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-nlp>=0.4.0->autokeras) (13.5.2)\n","Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-nlp>=0.4.0->autokeras) (0.1.8)\n","Collecting tensorflow-text (from keras-nlp>=0.4.0->autokeras)\n","  Downloading tensorflow_text-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.31.0)\n","Collecting kt-legacy (from keras-tuner>=1.1.0->autokeras)\n","  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (1.57.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (3.9.0)\n","Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (2.13.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (16.0.6)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (3.3.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (1.16.0)\n","Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (2.13.0)\n","Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (2.13.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (2.3.0)\n","Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (1.15.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.8.0->autokeras) (0.33.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->autokeras) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->autokeras) (2023.3.post1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->autokeras) (0.41.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (3.4.4)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (2.3.7)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2023.7.22)\n","Collecting namex (from keras-core->keras-nlp>=0.4.0->autokeras)\n","  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp>=0.4.0->autokeras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp>=0.4.0->autokeras) (2.16.1)\n","Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras-nlp>=0.4.0->autokeras) (0.14.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (1.3.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-nlp>=0.4.0->autokeras) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (2.1.3)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.8.0->autokeras) (3.2.2)\n","Installing collected packages: namex, kt-legacy, keras-core, keras-tuner, tensorflow-text, keras-nlp, autokeras\n","Successfully installed autokeras-1.1.0 keras-core-0.1.7 keras-nlp-0.6.2 keras-tuner-1.4.3 kt-legacy-1.0.5 namex-0.0.7 tensorflow-text-2.13.0\n","Collecting tensorboardX\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.1)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.6.2.2\n","Collecting mosaicml\n","  Downloading mosaicml-0.16.3-py3-none-any.whl (607 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m607.5/607.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from mosaicml) (6.0.1)\n","Requirement already satisfied: tqdm<5,>=4.62.3 in /usr/local/lib/python3.10/dist-packages (from mosaicml) (4.66.1)\n","Collecting torchmetrics<1.1,>=0.10.0 (from mosaicml)\n","  Downloading torchmetrics-1.0.3-py3-none-any.whl (731 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.6/731.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-optimizer<0.4,>=0.3.0 (from mosaicml)\n","  Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision<0.17,>=0.13.1 in /usr/local/lib/python3.10/dist-packages (from mosaicml) (0.15.2+cu118)\n","Requirement already satisfied: torch<2.1.1,>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from mosaicml) (2.0.1+cu118)\n","Requirement already satisfied: requests<3,>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from mosaicml) (2.31.0)\n","Requirement already satisfied: numpy<1.27.0,>=1.21.5 in /usr/local/lib/python3.10/dist-packages (from mosaicml) (1.23.5)\n","Requirement already satisfied: psutil<6,>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from mosaicml) (5.9.5)\n","Collecting coolname<3,>=1.1.0 (from mosaicml)\n","  Downloading coolname-2.2.0-py2.py3-none-any.whl (37 kB)\n","Requirement already satisfied: tabulate==0.9.0 in /usr/local/lib/python3.10/dist-packages (from mosaicml) (0.9.0)\n","Requirement already satisfied: py-cpuinfo<10,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from mosaicml) (9.0.0)\n","Collecting packaging<23,>=21.3.0 (from mosaicml)\n","  Downloading packaging-22.0-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-metadata<7,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mosaicml) (6.8.0)\n","Collecting mosaicml-cli<0.6,>=0.5.8 (from mosaicml)\n","  Downloading mosaicml_cli-0.5.17-py3-none-any.whl (231 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.0/231.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=5.0.0->mosaicml) (3.16.2)\n","Collecting argcomplete>=2.0.0 (from mosaicml-cli<0.6,>=0.5.8->mosaicml)\n","  Downloading argcomplete-3.1.2-py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting arrow>=1.2.2 (from mosaicml-cli<0.6,>=0.5.8->mosaicml)\n","  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting backoff>=2.2.1 (from mosaicml-cli<0.6,>=0.5.8->mosaicml)\n","  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Collecting gql[websockets]>=3.4.0 (from mosaicml-cli<0.6,>=0.5.8->mosaicml)\n","  Downloading gql-3.4.1-py2.py3-none-any.whl (65 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: prompt-toolkit>=3.0.29 in /usr/local/lib/python3.10/dist-packages (from mosaicml-cli<0.6,>=0.5.8->mosaicml) (3.0.39)\n","Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from mosaicml-cli<0.6,>=0.5.8->mosaicml) (3.20.3)\n","Collecting questionary>=1.10.0 (from mosaicml-cli<0.6,>=0.5.8->mosaicml)\n","  Downloading questionary-2.0.1-py3-none-any.whl (34 kB)\n","Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from mosaicml-cli<0.6,>=0.5.8->mosaicml) (13.5.2)\n","Collecting ruamel.yaml>=0.17.21 (from mosaicml-cli<0.6,>=0.5.8->mosaicml)\n","  Downloading ruamel.yaml-0.17.33-py3-none-any.whl (112 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from mosaicml-cli<0.6,>=0.5.8->mosaicml) (4.5.0)\n","Collecting validators>=0.20.0 (from mosaicml-cli<0.6,>=0.5.8->mosaicml)\n","  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.26.0->mosaicml) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.26.0->mosaicml) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.26.0->mosaicml) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.26.0->mosaicml) (2023.7.22)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.1.1,>=1.13.1->mosaicml) (3.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.1.1,>=1.13.1->mosaicml) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.1.1,>=1.13.1->mosaicml) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.1.1,>=1.13.1->mosaicml) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.1.1,>=1.13.1->mosaicml) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1.1,>=1.13.1->mosaicml) (3.27.4.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch<2.1.1,>=1.13.1->mosaicml) (16.0.6)\n","Collecting pytorch-ranger>=0.1.1 (from torch-optimizer<0.4,>=0.3.0->mosaicml)\n","  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n","Collecting lightning-utilities>=0.7.0 (from torchmetrics<1.1,>=0.10.0->mosaicml)\n","  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision<0.17,>=0.13.1->mosaicml) (9.4.0)\n","Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow>=1.2.2->mosaicml-cli<0.6,>=0.5.8->mosaicml) (2.8.2)\n","Collecting graphql-core<3.3,>=3.2 (from gql[websockets]>=3.4.0->mosaicml-cli<0.6,>=0.5.8->mosaicml)\n","  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.10/dist-packages (from gql[websockets]>=3.4.0->mosaicml-cli<0.6,>=0.5.8->mosaicml) (1.9.2)\n","Collecting websockets<11,>=10 (from gql[websockets]>=3.4.0->mosaicml-cli<0.6,>=0.5.8->mosaicml)\n","  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit>=3.0.29->mosaicml-cli<0.6,>=0.5.8->mosaicml) (0.2.6)\n","Collecting prompt-toolkit>=3.0.29 (from mosaicml-cli<0.6,>=0.5.8->mosaicml)\n","  Downloading prompt_toolkit-3.0.36-py3-none-any.whl (386 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.4/386.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->mosaicml-cli<0.6,>=0.5.8->mosaicml) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->mosaicml-cli<0.6,>=0.5.8->mosaicml) (2.16.1)\n","Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.21->mosaicml-cli<0.6,>=0.5.8->mosaicml)\n","  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (485 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.1.1,>=1.13.1->mosaicml) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.1.1,>=1.13.1->mosaicml) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->mosaicml-cli<0.6,>=0.5.8->mosaicml) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7.0->arrow>=1.2.2->mosaicml-cli<0.6,>=0.5.8->mosaicml) (1.16.0)\n","Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.6->gql[websockets]>=3.4.0->mosaicml-cli<0.6,>=0.5.8->mosaicml) (6.0.4)\n","Installing collected packages: coolname, websockets, validators, ruamel.yaml.clib, prompt-toolkit, packaging, graphql-core, backoff, argcomplete, ruamel.yaml, questionary, lightning-utilities, gql, arrow, mosaicml-cli, pytorch-ranger, torchmetrics, torch-optimizer, mosaicml\n","  Attempting uninstall: prompt-toolkit\n","    Found existing installation: prompt-toolkit 3.0.39\n","    Uninstalling prompt-toolkit-3.0.39:\n","      Successfully uninstalled prompt-toolkit-3.0.39\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 23.1\n","    Uninstalling packaging-23.1:\n","      Successfully uninstalled packaging-23.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed argcomplete-3.1.2 arrow-1.2.3 backoff-2.2.1 coolname-2.2.0 gql-3.4.1 graphql-core-3.2.3 lightning-utilities-0.9.0 mosaicml-0.16.3 mosaicml-cli-0.5.17 packaging-22.0 prompt-toolkit-3.0.36 pytorch-ranger-0.1.1 questionary-2.0.1 ruamel.yaml-0.17.33 ruamel.yaml.clib-0.2.7 torch-optimizer-0.3.0 torchmetrics-1.0.3 validators-0.22.0 websockets-10.4\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["prompt_toolkit"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Using TensorFlow backend\n"]}],"source":["!pip install autokeras\n","!pip install tensorboardX\n","!pip install mosaicml\n","import tensorflow as tf\n","import autokeras as ak\n","from keras.datasets import cifar10\n","\n","from tensorboardX import SummaryWriter\n","import matplotlib.pyplot as plt\n","import composer.functional as cf"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6p3Uzi1d9Bbc","executionInfo":{"status":"ok","timestamp":1696044291501,"user_tz":240,"elapsed":11094,"user":{"displayName":"Abhishek Donekal","userId":"08256368135897058810"}},"outputId":"3223ca4f-051b-455a-c3fc-75302cd0cce7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 6s 0us/step\n"]}],"source":["(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n","\n","# Take only 5000 samples from the training set\n","num_samples = 5000\n","train_images = train_images[:num_samples]\n","train_labels = train_labels[:num_samples]\n","\n","# Take only 5000 samples from the test set\n","test_images = test_images[:num_samples]\n","test_labels = test_labels[:num_samples]\n","\n","# The 'train_images', 'train_labels', 'test_images', and 'test_labels' now contain only 5000 samples each\n","# Normalize the pixel values to the range [0, 1]\n","train_images = train_images.astype('float32') / 255.0\n","test_images = test_images.astype('float32') / 255.0\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"wBQJNul29DTw","executionInfo":{"status":"ok","timestamp":1696044307801,"user_tz":240,"elapsed":139,"user":{"displayName":"Abhishek Donekal","userId":"08256368135897058810"}}},"outputs":[],"source":["\n","class LayerBlock(ak.Block):\n","    def build(self, hp, inputs=None):\n","        input_node = tf.nest.flatten(inputs)[0]\n","\n","        # First Dense Layer\n","        layer1 = tf.keras.layers.Dense(units=hp.Int(\"Layer_1\", min_value=32, max_value=1024, step=32),activation=hp.Choice(\"activation_1\", values=[\"relu\",\"softmax\", \"tanh\",\"sigmoid\"]))\n","        output_node1 = layer1(input_node)\n","\n","        # Second Dense Layer\n","        layer2 = tf.keras.layers.Dense(units=hp.Int(\"Layer_2\", min_value=32, max_value=1024, step=32),activation=hp.Choice(\"activation_2\", values=[\"relu\",\"softmax\", \"tanh\",\"sigmoid\"]))\n","        output_node2 = layer2(output_node1)\n","\n","        return output_node2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"EEcIzrWI9G6f","outputId":"9ffa4b1d-3e06-48af-e941-e73dfe0e6f14"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'import autokeras as ak\\n\\nclass LayerBlock(ak.Block):\\n\\n  def build(self, hp, inputs=None):\\n    input_node = tf.nest.flatten(inputs)[0]\\n\\n    # Tune number of layers\\n    num_layers = hp.Int(\\'num_layers\\', 1, 6)\\n\\n    x = input_node\\n    for i in range(num_layers):\\n      # Add dense layer\\n      layer = tf.keras.layers.Dense(\\n        units=hp.Int(f\\'units_{i}\\', 32, 512, step=32),\\n        activation=hp.Choice(f\\'activation_{i}\\', [\"linear\",\"relu\", \"leaky_relu\", \"tanh\",\"sigmoid\", \"softmax\", \"softplus\", \"elu\", \"selu\"])\\n      )\\n      x = layer(x)\\n\\n    return x'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["'''import autokeras as ak\n","\n","class LayerBlock(ak.Block):\n","\n","  def build(self, hp, inputs=None):\n","    input_node = tf.nest.flatten(inputs)[0]\n","\n","    # Tune number of layers\n","    num_layers = hp.Int('num_layers', 1, 6)\n","\n","    x = input_node\n","    for i in range(num_layers):\n","      # Add dense layer\n","      layer = tf.keras.layers.Dense(\n","        units=hp.Int(f'units_{i}', 32, 512, step=32),\n","        activation=hp.Choice(f'activation_{i}', [\"linear\",\"relu\", \"leaky_relu\", \"tanh\",\"sigmoid\", \"softmax\", \"softplus\", \"elu\", \"selu\"])\n","      )\n","      x = layer(x)\n","\n","    return x'''"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":478},"id":"nh7aMdLn9JXp","outputId":"ff2a302c-46aa-4fce-b69b-2d86f53b2983","executionInfo":{"status":"error","timestamp":1696044775507,"user_tz":240,"elapsed":453410,"user":{"displayName":"Abhishek Donekal","userId":"08256368135897058810"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 50 Complete [00h 00m 05s]\n","val_loss: 2.3767900466918945\n","\n","Best val_loss So Far: 1.8466334342956543\n","Total elapsed time: 00h 07m 23s\n","157/157 [==============================] - 4s 17ms/step - loss: 1.9713 - accuracy: 0.2840\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-dd06cd8c779a>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mauto_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauto_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autokeras/auto_model.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         return utils.evaluate_with_adaptive_batch_size(\n\u001b[1;32m    493\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autokeras/engine/tuner.py\u001b[0m in \u001b[0;36mget_best_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_best_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mkeras_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_distribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'keras_tuner.engine.tuner' has no attribute 'maybe_distribute'"]}],"source":["\n","input_node = ak.Input()\n","output_node = LayerBlock()(input_node)\n","output_node = ak.ClassificationHead()(output_node)\n","\n","# Create the AutoModel\n","auto_model = ak.AutoModel(\n","    tuner=\"bayesian\",\n","    inputs=input_node,\n","    outputs=output_node,\n","    overwrite=True,  # If True, overwrites the results of previous runs.\n","    max_trials=50,   # Maximum number of different Keras Models to try.\n","    seed=42,         # Random seed for reproducibility.\n","    directory=\"/my/directory\",  # Directory to store the results.\n","    project_name='my_custom_image_classifier',\n","    objective=\"val_loss\"  # Metric to optimize during the search.\n",")\n","\n","\n","# Train the model\n","auto_model.fit(train_images, train_labels, epochs=1)\n","print(auto_model.evaluate(test_images, test_labels))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"PLWyHmF8xqC8"},"outputs":[],"source":["tuner = auto_model.tuner\n","trial_ids = tuner.oracle.trials\n","trials_hparams=[]\n","score=[]\n","for trial_id in trial_ids:\n","    trial = auto_model.tuner.oracle.get_trial(trial_id)\n","    trial.best_step\n","    trial.metrics\n","    hparams = trial.hyperparameters.values\n","    score.append(trial.score)\n","  # Append to list\n","    trials_hparams.append(hparams)\n","\n","\n","import pandas as pd\n","df_bayesian = pd.DataFrame(trials_hparams)\n","df_bayesian['val_Loss']=score\n","df_bayesian"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"FO8vkCfltliv"},"outputs":[],"source":["\n","input_node = ak.Input()\n","output_node = LayerBlock()(input_node)\n","output_node = ak.ClassificationHead()(output_node)\n","\n","# Create the AutoModel\n","auto_model = ak.AutoModel(\n","    tuner=\"random\",\n","    inputs=input_node,\n","    outputs=output_node,\n","    overwrite=True,  # If True, overwrites the results of previous runs.\n","    max_trials=50,   # Maximum number of different Keras Models to try.\n","    seed=42,         # Random seed for reproducibility.\n","    directory=\"/my/directory\",  # Directory to store the results.\n","    project_name='my_custom_image_classifier',\n","    objective=\"val_loss\"  # Metric to optimize during the search.\n",")\n","\n","\n","# Train the model\n","auto_model.fit(train_images, train_labels, epochs=1)\n","print(auto_model.evaluate(test_images, test_labels))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"C8oj3qNbugr0"},"outputs":[],"source":["tuner = auto_model.tuner\n","trial_ids = tuner.oracle.trials\n","trials_hparams=[]\n","score=[]\n","for trial_id in trial_ids:\n","    trial = auto_model.tuner.oracle.get_trial(trial_id)\n","    trial.best_step\n","    trial.metrics\n","    hparams = trial.hyperparameters.values\n","    score.append(trial.score)\n","  # Append to list\n","    trials_hparams.append(hparams)\n","\n","\n","import pandas as pd\n","df_random = pd.DataFrame(trials_hparams)\n","df_random['val_Loss']=score\n","df_random"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"B0euPu9ttlvj"},"outputs":[],"source":["\n","input_node = ak.Input()\n","output_node = LayerBlock()(input_node)\n","output_node = ak.ClassificationHead()(output_node)\n","\n","# Create the AutoModel\n","auto_model = ak.AutoModel(\n","    tuner=\"greedy\",\n","    inputs=input_node,\n","    outputs=output_node,\n","    overwrite=True,  # If True, overwrites the results of previous runs.\n","    max_trials=50,   # Maximum number of different Keras Models to try.\n","    seed=42,         # Random seed for reproducibility.\n","    directory=\"/my/directory\",  # Directory to store the results.\n","    project_name='my_custom_image_classifier',\n","    objective=\"val_loss\"  # Metric to optimize during the search.\n",")\n","\n","\n","# Train the model\n","auto_model.fit(train_images, train_labels, epochs=1)\n","print(auto_model.evaluate(test_images, test_labels))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"OEEQdZMEyC-h"},"outputs":[],"source":["tuner = auto_model.tuner\n","trial_ids = tuner.oracle.trials\n","trials_hparams=[]\n","score=[]\n","for trial_id in trial_ids:\n","    trial = auto_model.tuner.oracle.get_trial(trial_id)\n","    trial.best_step\n","    trial.metrics\n","    hparams = trial.hyperparameters.values\n","    score.append(trial.score)\n","  # Append to list\n","    trials_hparams.append(hparams)\n","\n","\n","import pandas as pd\n","df_greedy = pd.DataFrame(trials_hparams)\n","df_greedy['val_Loss']=score\n","df_greedy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"vyZZxBT3tl63"},"outputs":[],"source":["\n","input_node = ak.Input()\n","output_node = LayerBlock()(input_node)\n","output_node = ak.ClassificationHead()(output_node)\n","\n","# Create the AutoModel\n","auto_model = ak.AutoModel(\n","    tuner=\"hyperband\",\n","    inputs=input_node,\n","    outputs=output_node,\n","    overwrite=True,  # If True, overwrites the results of previous runs.\n","    max_trials=50,   # Maximum number of different Keras Models to try.\n","    seed=42,         # Random seed for reproducibility.\n","    directory=\"/my/directory\",  # Directory to store the results.\n","    project_name='my_custom_image_classifier',\n","    objective=\"val_loss\"  # Metric to optimize during the search.\n",")\n","\n","\n","# Train the model\n","auto_model.fit(train_images, train_labels, epochs=1)\n","print(auto_model.evaluate(test_images, test_labels))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"aIRs29lCtl-W"},"outputs":[],"source":["tuner = auto_model.tuner\n","trial_ids = tuner.oracle.trials\n","trials_hparams=[]\n","score=[]\n","for trial_id in trial_ids:\n","    trial = auto_model.tuner.oracle.get_trial(trial_id)\n","    trial.best_step\n","    trial.metrics\n","    hparams = trial.hyperparameters.values\n","    score.append(trial.score)\n","  # Append to list\n","    trials_hparams.append(hparams)\n","\n","\n","import pandas as pd\n","df_hyperband = pd.DataFrame(trials_hparams)\n","df_hyperband['val_Loss']=score\n","df_hyperband"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"F0JmSm5A6bRi"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","df_bayesian.to_csv(\"/content/drive/MyDrive/Capsotn3/Capstone/Bayesian1.csv\")\n","df_random.to_csv(\"/content/drive/MyDrive/Capsotn3/Capstone/Random1.csv\")\n","df_greedy.to_csv(\"/content/drive/MyDrive/Capsotn3/Capstone/greedy1.csv\")\n","df_hyperband.to_csv(\"/content/drive/MyDrive/Capsotn3/Capstone/hyperband1.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qY-IOooqO-Ww"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Your data\n","x = df.index\n","y1 = df['layer_block_1/Layer_1']\n","y2 = df['val_Loss']\n","\n","# Create a figure and axis\n","fig, ax1 = plt.subplots()\n","\n","# Plot the first dataset on the primary y-axis\n","ax1.scatter(x, y1, label='Layer_1 units', color='b')\n","ax1.set_xlabel('Index')\n","ax1.set_ylabel('Layer_1 units', color='b')\n","ax1.tick_params(axis='y', labelcolor='b')\n","\n","# Create a secondary y-axis\n","ax2 = ax1.twinx()\n","\n","# Plot the second dataset on the secondary y-axis\n","ax2.plot(x, y2, label='Val_loss', color='r')\n","ax2.set_ylabel('Val_loss', color='r')\n","ax2.tick_params(axis='y', labelcolor='r')\n","\n","# Add legends\n","lines1, labels1 = ax1.get_legend_handles_labels()\n","lines2, labels2 = ax2.get_legend_handles_labels()\n","lines = lines1 + lines2\n","labels = labels1 + labels2\n","\n","\n","# Show the plot\n","plt.grid(True)\n","plt.title('Dual Y-Axis Plot')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"q-yaiR8WKeKx"},"source":["multiple layers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kNrfgJ3SKWrv"},"outputs":[],"source":["plt.figure(figsize=(10, 6))\n","plt.plot(df.index, df['val_Loss'], c='blue', marker='o', label='Loss')  # Corrected column name\n","plt.xlabel('Configuration Index')\n","plt.ylabel('Validation Loss')\n","plt.title('Hyperparameter Search Results')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YTzoKpW8Ks1A"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Your data\n","x = df.index\n","y1 = df['layer_block_1/num_layers']\n","y2 = df['val_Loss']\n","\n","# Create a figure and axis\n","fig, ax1 = plt.subplots()\n","\n","# Plot the first dataset on the primary y-axis\n","ax1.scatter(x, y1, label='Layer_1 units', color='b')\n","ax1.set_xlabel('Index')\n","ax1.set_ylabel('Layer_1 units', color='b')\n","ax1.tick_params(axis='y', labelcolor='b')\n","\n","# Create a secondary y-axis\n","ax2 = ax1.twinx()\n","\n","# Plot the second dataset on the secondary y-axis\n","ax2.plot(x, y2, label='Val_loss', color='r')\n","ax2.set_ylabel('Val_loss', color='r')\n","ax2.tick_params(axis='y', labelcolor='r')\n","\n","# Add legends\n","lines1, labels1 = ax1.get_legend_handles_labels()\n","lines2, labels2 = ax2.get_legend_handles_labels()\n","lines = lines1 + lines2\n","labels = labels1 + labels2\n","\n","\n","# Show the plot\n","plt.grid(True)\n","plt.title('Dual Y-Axis Plot')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jwRpx4NZLCfA"},"outputs":[],"source":["df.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AZRxlCphK6Wh"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Your data\n","x = df.index\n","y1 = df['layer_block_1/units_0']\n","y2 = df['val_Loss']\n","\n","# Create a figure and axis\n","fig, ax1 = plt.subplots()\n","\n","# Plot the first dataset on the primary y-axis\n","ax1.scatter(x, y1, label='Layer_1 units', color='b')\n","ax1.set_xlabel('Index')\n","ax1.set_ylabel('Layer_1 units', color='b')\n","ax1.tick_params(axis='y', labelcolor='b')\n","\n","# Create a secondary y-axis\n","ax2 = ax1.twinx()\n","\n","# Plot the second dataset on the secondary y-axis\n","ax2.plot(x, y2, label='Val_loss', color='r')\n","ax2.set_ylabel('Val_loss', color='r')\n","ax2.tick_params(axis='y', labelcolor='r')\n","\n","# Add legends\n","lines1, labels1 = ax1.get_legend_handles_labels()\n","lines2, labels2 = ax2.get_legend_handles_labels()\n","lines = lines1 + lines2\n","labels = labels1 + labels2\n","\n","\n","# Show the plot\n","plt.grid(True)\n","plt.title('Dual Y-Axis Plot')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZUZMEa9OK8ZI"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Your data\n","x = df.index\n","y1 = df['layer_block_1/units_1']\n","y2 = df['val_Loss']\n","\n","# Create a figure and axis\n","fig, ax1 = plt.subplots()\n","\n","# Plot the first dataset on the primary y-axis\n","ax1.scatter(x, y1, label='Layer_2 units', color='k')\n","ax1.set_xlabel('Index')\n","ax1.set_ylabel('Layer_2 units', color='k')\n","ax1.tick_params(axis='y', labelcolor='k')\n","\n","# Create a secondary y-axis\n","ax2 = ax1.twinx()\n","\n","# Plot the second dataset on the secondary y-axis\n","ax2.plot(x, y2, label='Val_loss', color='r')\n","ax2.set_ylabel('Val_loss', color='r')\n","ax2.tick_params(axis='y', labelcolor='r')\n","\n","# Add legends\n","lines1, labels1 = ax1.get_legend_handles_labels()\n","lines2, labels2 = ax2.get_legend_handles_labels()\n","lines = lines1 + lines2\n","labels = labels1 + labels2\n","\n","\n","# Show the plot\n","plt.grid(True)\n","plt.title('Dual Y-Axis Plot')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E_5Rm11CK8bo"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Your data\n","x = df.index\n","y1 = df['layer_block_1/units_2']\n","y2 = df['val_Loss']\n","\n","# Create a figure and axis\n","fig, ax1 = plt.subplots()\n","\n","# Plot the first dataset on the primary y-axis\n","ax1.scatter(x, y1, label='Layer_3 units', color='k')\n","ax1.set_xlabel('Index')\n","ax1.set_ylabel('Layer_3 units', color='k')\n","ax1.tick_params(axis='y', labelcolor='k')\n","\n","# Create a secondary y-axis\n","ax2 = ax1.twinx()\n","\n","# Plot the second dataset on the secondary y-axis\n","ax2.plot(x, y2, label='Val_loss', color='r')\n","ax2.set_ylabel('Val_loss', color='r')\n","ax2.tick_params(axis='y', labelcolor='r')\n","\n","# Add legends\n","lines1, labels1 = ax1.get_legend_handles_labels()\n","lines2, labels2 = ax2.get_legend_handles_labels()\n","lines = lines1 + lines2\n","labels = labels1 + labels2\n","\n","\n","# Show the plot\n","plt.grid(True)\n","plt.title('Dual Y-Axis Plot')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Shpnr-CK8eY"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Your data\n","x = df.index\n","y1 = df['layer_block_1/units_3']\n","y2 = df['val_Loss']\n","\n","# Create a figure and axis\n","fig, ax1 = plt.subplots()\n","\n","# Plot the first dataset on the primary y-axis\n","ax1.scatter(x, y1, label='Layer_4 units', color='k')\n","ax1.set_xlabel('Index')\n","ax1.set_ylabel('Layer_4 units', color='k')\n","ax1.tick_params(axis='y', labelcolor='k')\n","\n","# Create a secondary y-axis\n","ax2 = ax1.twinx()\n","\n","# Plot the second dataset on the secondary y-axis\n","ax2.plot(x, y2, label='Val_loss', color='r')\n","ax2.set_ylabel('Val_loss', color='r')\n","ax2.tick_params(axis='y', labelcolor='r')\n","\n","# Add legends\n","lines1, labels1 = ax1.get_legend_handles_labels()\n","lines2, labels2 = ax2.get_legend_handles_labels()\n","lines = lines1 + lines2\n","labels = labels1 + labels2\n","\n","\n","# Show the plot\n","plt.grid(True)\n","plt.title('Dual Y-Axis Plot')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fbUexVMVK8hB"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Your data\n","x = df.index\n","y1 = df['layer_block_1/units_3']\n","y2 = df['val_Loss']\n","\n","# Create a figure and axis\n","fig, ax1 = plt.subplots()\n","\n","# Plot the first dataset on the primary y-axis\n","ax1.scatter(x, y1, label='Layer_4 units', color='k')\n","ax1.set_xlabel('Index')\n","ax1.set_ylabel('Layer_4 units', color='k')\n","ax1.tick_params(axis='y', labelcolor='k')\n","\n","# Create a secondary y-axis\n","ax2 = ax1.twinx()\n","\n","# Plot the second dataset on the secondary y-axis\n","ax2.plot(x, y2, label='Val_loss', color='r')\n","ax2.set_ylabel('Val_loss', color='r')\n","ax2.tick_params(axis='y', labelcolor='r')\n","\n","# Add legends\n","lines1, labels1 = ax1.get_legend_handles_labels()\n","lines2, labels2 = ax2.get_legend_handles_labels()\n","lines = lines1 + lines2\n","labels = labels1 + labels2\n","\n","\n","# Show the plot\n","plt.grid(True)\n","plt.title('Dual Y-Axis Plot')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jd2GaC1KK8jx"},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oUC7wRo7K8mE"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aLsCFX7mK8og"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KHyKc2nfK8ri"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rbw4wVRrK8uQ"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"k6e7tc0bKif5"},"source":["Old results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3mdS5oh7FTvw"},"outputs":[],"source":["import pandas as pd\n","\n","first_row = df.loc[df['val_Loss'].argmin()]\n","# Select numeric columns\n","numeric_cols = df.select_dtypes(include=['integer', 'float']).columns\n","\n","# Calculate similarity of each row vs first row\n","from scipy.spatial.distance import cosine\n","\n","similarity = df.apply(lambda x: 1 - cosine(x[numeric_cols], first_row[numeric_cols]), axis=1)\n","\n","# Add similarities as new column\n","df['Cosine_similarity'] = similarity\n","\n","\n","# Create a scatter plot\n","plt.figure(figsize=(8, 6))\n","plt.scatter(df['Cosine_similarity'], df['val_Loss'], marker='o', c='b', label='Data Points')\n","\n","# Label the axes and add a legend\n","plt.xlabel('Similarity to Best Architechture')\n","plt.ylabel('Validation Loss')\n","plt.legend()\n","\n","# Show the plot\n","plt.title('Scatter Plot of Similarity(Cosine_similarity) vs. Validation Loss')\n","plt.grid(True)\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pIdtHreyB6Ia"},"outputs":[],"source":["from scipy.spatial.distance import euclidean\n","\n","# Calculate Euclidean distance instead of cosine similarity\n","similarity = df.apply(lambda x: 1/(1 + euclidean(x[numeric_cols], first_row[numeric_cols])), axis=1)\n","\n","# Invert distance to get similarity\n","similarity = 1/similarity\n","\n","# Add similarities as new column\n","df['euclidean_distance'] = similarity\n","\n","\n","# Create a scatter plot\n","plt.figure(figsize=(8, 6))\n","plt.scatter(df['euclidean_distance'], df['val_Loss'], marker='o', c='b', label='Data Points')\n","\n","# Label the axes and add a legend\n","plt.xlabel('Similarity to Best Architechture')\n","plt.ylabel('Validation Loss')\n","plt.legend()\n","\n","# Show the plot\n","plt.title('Scatter Plot of Similarity(euclidean_distance) vs. Validation Loss')\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HKYeqAektJab"},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WZpTbMJ4GVyK"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}